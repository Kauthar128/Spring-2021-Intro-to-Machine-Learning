{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Machine Learning, Data Matrix\n",
    "\n",
    "# Lecture 1 (Mon, Jan 11)\n",
    "\n",
    "A machine learning problem generally has three parts\n",
    "\n",
    "* A task $T$\n",
    "* A performance measure $P$\n",
    "* An experience $E$\n",
    "\n",
    "A computer program learns from experience $E$ with respect to some task $T$ and performance measure $P$ if it improves at task $T$, measured by $P$, with experience $E$. For example,\n",
    "\n",
    "* **Task**: Identify pictures as having cats or not having cats in them\n",
    "* **Performance measure**: The proportion of pictures with cats does our computer properly identify\n",
    "* **Experience**: The computer will be given 500 images with cats and 500 images without cats, each with labels of \"cat\" or \"no cat\"\n",
    "\n",
    "Machine learning tasks are generally too difficult for pre-designed programs to do. Instead, we write programs for computers to learn to solve them. For example, we might want a machine learning algorithm to determine if a picture has a cat in it:\n",
    "\n",
    "* We **WOULD NOT** give a computer set of instructions to decide how to find cats. (What would the instructions be?!)\n",
    "\n",
    "* We **WOULD** feed many cat pictures and non-cat pictures to the computer, let label them according to some instructions (usually with some randomly initialized parameters), and give it some instructions for how to tweak its labels, and \n",
    "\n",
    "There are many types of tasks. Two large classes of tasks are supervised and unsupervised learning tasks.\n",
    "\n",
    "* **Supervised learning algorithms** have an experience of observing a dataset of examples *with* labels a correct algorithm would output.\n",
    "\n",
    "* **Unsupervised learning algorithms** have an experience of observing a dataset *without* labels and seek to learn useful patterns in the dataset.\n",
    "    \n",
    "There are some other types of problems, but these groups are most common and the primary focus of this class. Below, we discuss some common tasks in each category. It is not meant to be an exhaustive list but rather a brief outline of what the tasks are, examples of each, and some common methods for attacking these tasks.\n",
    "\n",
    "It should be noted that machine learning practitioners commonly use multiple methods, build methods customized to their problems, and create pipelines using multiple methods in a specified sequence.\n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "For most supervised learning problems, we have a dataset of $n$ **examples** or **data points**, which can be presented as points in space\n",
    "\n",
    "$$ x_i=(x_{i1}, ..., x_{id})\\in\\mathbb{R}^d$$\n",
    "\n",
    "and we try to predict a function $f:\\mathbb{R}^d\\to\\mathbb{R}^m$ mapping these points $x_i$ to some **label** or **target** $y_i\\in\\mathbb{R}^m$. Each component of $x_i$ is usually called a **feature** or an **attribute**.\n",
    "\n",
    "### Classification Problems\n",
    "\n",
    "In a classification task, the learning algorithm tries to predict which of $k$ disjoint categories a datapoint belongs to--e.g. to estimate a function $f:\\mathbb{R}^d\\to\\{1, ..., k\\}$.\n",
    "\n",
    "Identifying pictures of cats is an example of this problem: the categories are \"cat\" and \"no cat,\" which are mutually exclusive. (Keep in mind an image is stored in a computer as a numerical value representing the intensity of red, blue, and green colors in each pixel of the image, which may easily be stored as a very high-dimensional point.)\n",
    "\n",
    "Common methods for classification include logistic regresion, $k$-nearest neighbors, the Bayes and naive Bayes classifiers, discriminant analysis (LDA and QDA), decision trees, random forests, and support vector machines--all of which will be covered in this course--as well as neural networks (MLPs, CNNs, RNNs), which are beyond the scope of this course.\n",
    "\n",
    "### Regression Problems\n",
    "\n",
    "In a regression task, the learning algorithm tries to predict a numerical $m$-vector given an $d$-dimensional input example--e.g. to estimate a function $f:\\mathbb{R}^d\\to\\mathbb{R}^m$.\n",
    "\n",
    "An example is predicting the price for which a house will sell given information on the house--the number of bedrooms, the number of bathrooms, the floorspace, the size of the surrounding yard, whether or not it has a pool, etc. Here, as in many of the problems we will cover, $m=1$, meaning we will predict only one output variable.\n",
    "\n",
    "Common methods for regression include linear regression, ridge and LASSO regression, decision trees, random forest, and support vector machines--all of which will be covered in this course--as well as linear models and neural networks (MLPs, CNNs, RNNs), which are beyond the scope of this course. \n",
    "\n",
    "## Unsupervised Learning\n",
    "\n",
    "In unsupervised learning, we do not have the benefit of knowing some of the results we need to find. It is usually a somewhat less structured search for useful patterns in a dataset.\n",
    "\n",
    "### Clustering Problems\n",
    "\n",
    "A clustering task is one that tries to find which datapoints are similar to one another, in some sense that we do not necessarily define in advance.\n",
    "\n",
    "Common methods for clustering are K-means and hierarchical clustering--both of which we will cover in the course--as well as mean-shift clustering, DBSCAN, Gaussian mixture models, and self-organizing maps, which are beyond the scope of this course.\n",
    "\n",
    "### Dimensionality Reduction\n",
    "\n",
    "In a dimensionality reduction task, the goal is to represent a dataset using fewer features without losing patterns in \n",
    "\n",
    "For example, if we have a 1-megapixel color picture as a datapoint, it would have 1 million pixels and we would store three numbers (R, G, and B values) for each pixel, meaning the dimension of the image would be 3 million. It is sometimes far too slow to use datapoints in $\\mathbb{R}^{3000000}$ in machine learning algorithms. It is frequently helpful to find ways to store datapoints in lower-dimensional spaces such that important information is not lost. The idea is similar to compression.\n",
    "\n",
    "Common methods for dimensionality reduction are discriminant analysis (LDA and QDA), and principal components analysis (PCA)--which we will cover in the course--as well as autoencoders and word-embeddings, which are beyond the scope of this course.\n",
    "\n",
    "### Anomaly Detection\n",
    "\n",
    "In an anomaly detection task, the goal is to find unusual patterns in data.\n",
    "\n",
    "An example is credit card companies trying to detect unusual usage of a credit card. If they can detect unusual activity, they sometimes deactive credit cards to avoid fraud. False positives may cause problems for legitimate customers, but cards deactivated due to actual fraud can prevent further damage. \n",
    "\n",
    "### Denoising\n",
    "\n",
    "In denoising, the goal is to uncover some original dataset that has been corrupted by some sort of noise, whether we mean noisy sounds or random error. In all cases, the goal is to find a sometimes-faint signal within some noise.\n",
    "\n",
    "Denoising is not a task we will cover explicitly in the course.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* If you are speaking into a phone while riding in a car, the road noise can cause the voice signal not to be transmitted clearly\n",
    "* Noise-cancelling headphones try to counteract noise to pass through clear audio\n",
    "* Random errors in measurements in particle physics make the signal difficult to extract\n",
    "* Financial instruments like stocks can fluctuate at random while there is an underlying cause of general trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2 (Wed, Jan 13)\n",
    "\n",
    "# Data Matrix\n",
    "\n",
    "In this section, we will cover how data is frequently stored such that it can be used by machine learning methods. It should not be thought that this is the only way or always the best way to store data, but it will be a series of conventions used in many fields.\n",
    "\n",
    "For many problems, we will have a **dataset** consisting of some number $n$ points in $\\mathbb{R}^d$ that we will store in a matrix\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "x_{11} & x_{12} & \\cdots & x_{1d}\\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2d}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_{n1} & x_{n2} & \\cdots & x_{nd}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The $i$th *row* $x_i = (x_{i1}, x_{i2}, ..., x_{id})\\in\\mathbb{R}^d$ is the $i$th point in the dataset. These points have many names in different fields: **points, datapoints, examples, vectors, records, feature-vectors**. In some sources, these points $x_i$ are denoted $\\mathbf{x}_i$, but it should be clear that $x$ with a single subscripts indicates a point while $x$ with two subscripts is the component of a point.\n",
    "\n",
    "The $j$th *column* $X_j=(x_{1j}, x_{2j}, ..., x_{nj})\\in\\mathbb{R}^n$ is the $j$th component of each point in the dataset. These are likewise called by many names dependent on field: **features, attributes, variables, dimensions, properties, fields**. In some cases, each column can be considered a random sample of a random variable, or the rows of the matrix $X$ can be considered a random sample of vector-valued random variables.\n",
    "\n",
    "The number of points $n$ is the **size** of the dataset and the length of the points $d$ is called the **dimensionality** of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Problems\n",
    "\n",
    "**Regression problems** are problems where we try to predict a numerical output value given some input datapoint based on some examples ($x_i$, $y_i$) of input datapoints with known outputs or **targets**. This will be the task of the machine learning problem.\n",
    "\n",
    "## Examples\n",
    "\n",
    "1. If we have a dataset of workers in a certain position of numbers of years of experience as an input and salary, we might want to predict salaries we don't know based on the years of experience a person has.\n",
    "\n",
    "1. If we have a dataset of variables about houses (floorspace, number of bedrooms, number of bathrooms, number of stories, age of the house) along with their selling prices, we might want to predict selling prices of homes not in the dataset based on the other variables about the house.\n",
    "\n",
    "1. If we have a dataset of variables about countries (average salary, average education of citizens, death rate, birth rate, infant mortality rate, etc.) along with their GDP, we might want to predict the GDP of countires not in the dataset based on the other variables about the country.\n",
    "\n",
    "1. If we have a dataset of seasonal variables about NBA basketball teams (points per game, turnovers per game, point differential, rebounds per game, blocks per game, etc.) and the numbers of wins they had in different seasons, we might want to take the statistics of a team early in a season to try to predict the number of wins they will have and average number of points per game.\n",
    "\n",
    "## Types of Regression Problems\n",
    "\n",
    "There are different types of regression problems based on the numbers of input variables and output variables.\n",
    "\n",
    "* A **simple** regression problem predicts an output variable with just one input variable like Example 1.\n",
    "\n",
    "* A **multiple** regression problem predicts an output variable with more than one input variable like Examples 2 and 3.\n",
    "\n",
    "* A **multivariate** regression problem predicts more than one output variables like Example 4.\n",
    "\n",
    "## The Math of a Regression Problem\n",
    "\n",
    "All of these regression problems have some things in common: there are example datapoints with outputs and we want to predict the outputs for new datapoints. Consider a $d$-dimensional point, or vector, $x_i\\in\\mathbb{R}^d$ and denote $x_i=(x_{i1},x_{i2},...,x_{id})$. $x_i$ maps to an output $y_i\\in\\mathbb{R}^m$. (In statistics, the components of the vector $x_1$ are more frequently called **predictors** or **independent variables** and the $y_i$ values are more frequently called **responses** or **dependent variables**.)\n",
    "\n",
    "In a perfect world, a solution to a (univariate) regression problem will find a function $f:\\mathbb{R}^d\\to\\mathbb{R}$ that can do two things:\n",
    "\n",
    "1. Mapping each example $x_i$ in a dataset to its output $y_i=f(x_i)$\n",
    "1. Generalize to successfully predict outputs of new datapoints\n",
    "\n",
    "In reality, $f$ will not always map each input $x_i$ values to each $y_i$ value perfectly or generalize to new inputs well, but we try to get as close to these ideals as possible.\n",
    "\n",
    "## Regression Algorithms\n",
    "\n",
    "There are a number of popular approaches to regression problems, including the following.\n",
    "\n",
    "* linear regression\n",
    "* lasso regression\n",
    "* ridge regression\n",
    "* decision trees\n",
    "* support vector machines\n",
    "* neural networks\n",
    "\n",
    "In the near term, we will consider the first three approaches as they are quite similar. As an added bonus, they all use a numerical optimization scheme called gradient descent, which is one of the main algorithms of machine learning.\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "We will assume the function $f$ we aim to predict is linear in some parameters $\\beta_0,...,\\beta_d$ so that our predicted function will be\n",
    "\n",
    "$$\n",
    "f(x_i)=\\beta_0 + \\sum\\limits_{k=1}^d \\beta_k x_{ik}=\\beta_0+\\beta_1 x_{i1}+\\cdots+\\beta_d x_{id}\n",
    "$$\n",
    "\n",
    "and we will try to choose $\\beta_0,...,\\beta_d$ that will minimize a loss function on a training dataset $(x_1,y_1),...,(x_n,y_n)$. This loss function will be small if each $f(x_i)$ is near each $y_i$, which is what we want\n",
    "\n",
    "### Note\n",
    "\n",
    "It is a common misconception that \"linear regression\" must fit linear functions to data, but the \"linear\" part of linear regression refers to the fact that $f$ is linear with respect to $\\beta_0,...,\\beta_d$, not with respect to $x_i$, so it is certainly possible to apply some preprocessing to the datapoints, which in effect, fits a nonlinear surface.\n",
    "\n",
    "For example, if each $x_i\\in\\mathbb{R}^1$, we can fit a parabola by manipulating each $x_i$ into $x_i^*=(x_i,x_i^2)$ so that our predicted function would be\n",
    "\n",
    "$$f(x_i)=\\beta_0+\\beta_1 x_i+\\beta_2 x_i^2.$$\n",
    "\n",
    "While we will discuss only points in the form $x_i=(x_{i1},...,x_{id})$, keep in mind that we can always create new variables from the data, preprocess the data into different forms, and so on, to consider some (kernel) function of the data $g(x_i)$ as the inputs, as long as the function is differentiable (or at least piecewise differentiable). The main point here is that linear regression can learn to represent functions far beyond simply lines and planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression by Ordinary Least Squares (OLS)\n",
    "\n",
    "Recall that we have a labeled dataset $(x_1,y_1)$, ..., $(x_n,y_n)$ with each $x_i\\in\\mathbb{R}^d$ and each $y_i\\in\\mathbb{R}$ and our goal is to find a function $f$ that maps the $x_i$'s to the $y_i$'s as well as possible, and, we hope, is effective at mapping unknown datapoints to appropriate outputs.\n",
    "\n",
    "In the **ordinary least squares** method, we try to minimize a the **sum of squared differences** between the real outputs $y_1, ..., y_n$ and the predicted outputs $f(x_1)$, ..., $f(x_n)$. In other words, the loss function in this method is\n",
    "\n",
    "$$L(\\beta)=\\sum\\limits_{i=1}^n \\left(f(x_i)-y_i\\right)^2 = \\sum\\limits_{i=1}^n \\left(x_i^T\\beta-y_i\\right)^2,$$\n",
    "\n",
    "which we will call a **loss function**, where\n",
    "\n",
    "$$\n",
    "X=\\begin{pmatrix}\n",
    "1 & x_{11} & x_{12} & \\cdots & x_{1d}\\\\\n",
    "1 & x_{21} & x_{22} & \\cdots & x_{2d}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "1 & x_{n1} & x_{n2} & \\cdots & x_{nd}\n",
    "\\end{pmatrix}\n",
    "\\hspace{2cm}y=\\begin{pmatrix}\n",
    "y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n",
    "\\end{pmatrix}\n",
    "\\hspace{2cm}\\beta=\\begin{pmatrix}\n",
    "\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_d\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "This matrix is the same as what we used above, except we added a column of ones to the left for convenience.\n",
    "\n",
    "### Norms and Distance Metrics\n",
    "\n",
    "Let $d(x_1,x_2)=\\|x_1-x_2\\|$ be the distance from $x_1$ to $x_2$. The specific formula we use is called the **distance metric** and the function $\\|\\cdot\\|:\\mathbb{R}^d\\to[0,\\infty)$ is called a **norm**. The most-used norms are from the family of $L^p$ distances for each number $p>0$. (Note that mathematicians would likely refer to this as simply the $p$-norm for a finite dimensional space.) Distances between points are computed with the $L^p$-norm as\n",
    "\n",
    "$$\\left\\|x_1-x_2\\right\\|_p =\\left(\\sum\\limits_{i=1}^d |x_{1i}-x_{2i}|^p\\right)^{1/p}$$\n",
    "\n",
    "* If $p=1$, we get what is called the **taxi-cab** or **Manhattan distance** because, geometrically, the distance from (4, 6) to (8, 15) is the distance to drive along city blocks from 4th street and 6th avenue to 8th street and 15th avenue. It is computed as\n",
    "\n",
    "$$\\left\\|x_1-x_2\\right\\|_1= \\left|x_{11}-x_{21}\\right|+\\cdots+\\left|x_{1d}-x_{2d}\\right|$$\n",
    "\n",
    "* If $p=2$, we get the familiar **Euclidean distance**, the straight-line distance in flat space you have certainly encountered in elementary algebra and calculus courses,\n",
    "\n",
    "$$\n",
    "\\left\\|x_1-x_2\\right\\|_2=\\sqrt{\\left(x_{11}-x_{21}\\right)^2+\\cdots+\\left(x_{1d}-x_{2d}\\right)^2}$$\n",
    "\n",
    "* If $p=\\infty$, we get what is called the **supremum** or **maximum distance** and it is calculated as\n",
    "\n",
    "$$\\left\\|x_1-x_2\\right\\|_\\infty= \\max\\limits_{i=1,...,d}\\left|x_{1i}-x_{2i}\\right|=\\max\\{|x_{11}-x_{21}|, ..., |x_{1d}-x_{2d}|\\}$$\n",
    "\n",
    "For now, let's we will use the Euclidean distance, but in other areas, different $L^p$ norms may be used as may other <a href=\"https://en.wikipedia.org/wiki/Norm_(mathematics)#Definition\">norms</a> (see 2.5 in Goodfellow et. al.).\n",
    "\n",
    "## Back to OLS\n",
    "\n",
    "Given this, we can rewrite the loss function as\n",
    "\n",
    "$$L(\\beta)=\\|X\\beta-y\\|^2_2=(X\\beta-y)^T(X\\beta-y),$$\n",
    "\n",
    "where the $T$ subscript represents the **transpose** of a matrix. Here, $X$ and $y$ are constants derived from the dataset, so the $\\beta$ values are the only unknowns, so we need to find the $\\beta$ values that minimize the loss function $L$. In other words, we need to solve a minimization problem\n",
    "\n",
    "$$\\min\\limits_\\beta\\,L(\\beta)=\\min\\limits_\\beta\\,(X\\beta - y)^T(X\\beta - y).$$\n",
    "\n",
    "We should note that these $\\beta$ values are called **parameters** of the model, which are values that are estimated by the model automatically from the data.\n",
    "\n",
    "In multivariate calculus, the approach to minimize a differentiable function with unbounded domain is to take derivatives with respect to $\\beta_0, ..., \\beta_d$, set them all equal to zero, solve, and compare the function at these critical values. This may seem difficult, but we can actually do it simply for ordinary least squares. Before we take derivatives, let's convert the loss function into a (longer but) simpler form. Transposes can be applied to sums of matrices separately, so\n",
    "\n",
    "$$L(\\beta)=((X\\beta)^T-y^T)(X\\beta-y).$$\n",
    "\n",
    "Using the distributive property of matrix multiplication,\n",
    "\n",
    "$$L(\\beta)=(X\\beta)^T X\\beta-(X\\beta)^T y-y^T X\\beta+y^T y$$\n",
    "\n",
    "If we realize $y$ and $X\\beta$ are both matrices of shape $n\\times 1$, then we should have $(X\\beta)^T y=y^T X\\beta$, so the loss function is\n",
    "\n",
    "$$L(\\beta)=(X\\beta)^T X\\beta-2(X\\beta)^T y+y^T y$$\n",
    "\n",
    "Since $(AB)^T=B^TA^T$ for matrices, we can simplify the terms as\n",
    "\n",
    "$$L(\\beta)=\\beta^T X^T X\\beta-2\\beta^T X^T y+y^T y$$\n",
    "\n",
    "Now, of course, this is a scalar (because, in the end, the loss is just a number--the sum of squared errors), so we can take the derivatives with respect to $\\beta_1$, ..., $\\beta_d$ and put those into a vector as\n",
    "\n",
    "$$\\nabla L(\\beta)=2X^T X\\beta-2X^T y$$\n",
    "\n",
    "As in multivariate calculus, we set this whole vector equal to 0 and solve for the estimated version of $\\beta$ as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "2X^T X\\beta-2X^T y &= 0\\\\\n",
    "X^T X\\beta &= X^T y.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then, if $X^T X$ is an invertible matrix, then we can multiply both sides of the equation by its inverse to solve for $\\beta$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "(X^T X)^{-1}(X^T X\\beta) &= (X^T X)^{-1}X^T y\\\\\n",
    "\\beta &=(X^T X)^{-1}X^T y.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "At long last, we have a formula for the exact solution for the $\\beta$ values that minimize the loss function.\n",
    "\n",
    "#### Linear Algebra Notes\n",
    "\n",
    "* The formula above holds only if the inverse of the matrix $X^T X$ exists. Assuming $n\\geq d$, the inverse exists when the columns of $X$ are linearly independent. (See <a href=\"https://www.khanacademy.org/math/linear-algebra/matrix-transformations/matrix-transpose/v/lin-alg-showing-that-a-transpose-x-a-is-invertible\">this video</a> or pretty much any linear algebra book.)\n",
    "\n",
    "* If you have studied linear algebra, you might recognize $(X^T X)^{-1}X^T$ is the <a href=\"https://mathworld.wolfram.com/Moore-PenroseMatrixInverse.html\">Moore-Penrose pseudoinverse</a> of $X$.\n",
    "\n",
    "Anyway, the formula for $\\beta$ does not look so nice to do by hand since it requires a matrix multiplication, a matrix inverse, and two more matrix multiplications, but a computer can complete these tasks quickly. (The <a href=\"https://mathworld.wolfram.com/Moore-PenroseMatrixInverse.html\">best algorithms</a> for matrix multiplication and matrix inverses for $n\\times n$ matrices each have computational complexity less than $O(n^3)$, so doing a few of these is no problem, even for quite large matrices.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing a Regression Model\n",
    "\n",
    "If we have a dataset of labeled data, a very common approach is to randomly split the dataset into two parts: the training set and the testing set. We remove the labels from the test set, \"train\" the model with the training set, use the resulting model to attempt to make predictions for the test set, and then measure performance.\n",
    "\n",
    "There are no strict rules here, but it is common to use 60\\% train 40\\% test, although folks like Andrew Ng have argued that a much smaller test sets are reasonable if the dataset is very large--e.g. datasets with millions of datapoints are not uncommon in some fields. This way, we can measure the success of our regression model on data it has never seen (the testing set). Once we become confident our model works well in this way, we can be more confident that it will **generalize** well in the real world.\n",
    "\n",
    "My preferred approach is to use the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">train_test_split</a> function from the <a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\">scikit-learn.model_selection</a> library to randomly assign a specified percentage (usually 50-75%) of the dataset to the training set and the rest in the test set.\n",
    "\n",
    "### Hyperparameters and Dev Sets\n",
    "\n",
    "In some models, there are **hyperparameters** to tune. These are settings the user specifies before running the algorithms which may have an impact on performance. In this case, the test set is frequently split in half into \"dev\" and \"test\" sets. The dev set is used for tuning the hyperparameters before testing the model on unknown test sets. More on that later.\n",
    "\n",
    "## Performance Metrics for Regression\n",
    "\n",
    "Let's consider a few performance metrics in common usage for regression.\n",
    "\n",
    "With linear regression, we generally have the unfortunate situation that the model we construct is not perfect even on the training set. Therefore, we first need to consider the performance on the training data to which it was fit just to see how well the model fits to the training data. The formulas for the common metrics are not particularly interesting, so we just state what they represent and what value they should ideally have:\n",
    "\n",
    "* **Coefficient of determination** $R^2$ - the fraction of the variation in the data explained by the model. It is, in a sense, a measure of the strength of the linear relationship between the variables. Ideally, it will be near 1.\n",
    "\n",
    "* **Sum of squared error (SSE)** - the loss function we have used. Ideally, it will be as small as possible.\n",
    "\n",
    "* **Mean squared error (MSE)** is simply the SSE divided by the number of examples we test. It is frequently better because it makes little sense to measure success in a way that is so depedent on the dataset size. Ideally, it should of course be small.\n",
    "\n",
    "* **Mean absolute error (MAE)** - the mean of the absolute errors between the points and the fitted function. Ideally, it will be as small as possible.\n",
    "\n",
    "If these values are far from their ideal values for the training set, the model does not even fit the training data well, so it probably will not fit the testing data well. The ordinary least squares solution finds the optimal parameters for a linear fit, so poor performance on the training set means the data do not have a strong linear relationship.\n",
    "\n",
    "Some preprocessing of the data might make it work better. For example, you can apply a logarithm to a variable if there's a linear relationship with that variable on a log scale. See the (free) classic book <a href=\"https://web.stanford.edu/~hastie/ElemStatLearn/\">*Elements of Statistical Learning*</a> by Hastie, et. al., section 2.6.3 for an introduction on linear basis expansions.\n",
    "\n",
    "Second, we need to consider the performance on the testing data. We generally should consider the MSE or MAE.\n",
    "\n",
    "## Ordinary Least Squares Code\n",
    "\n",
    "Before we write some code for ordinary least squares, let's import some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# increase the width of boxes in the notebook file (this is only cosmetic)\n",
    "np.set_printoptions(linewidth=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a class for using ordinary least squares in this way to fit the model and to predict outputs for unknown inputs. We will use the scikit-learn pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinaryLeastSquaresExact:\n",
    "        \n",
    "    # fit the model to the data\n",
    "    def fit(self, X, y):\n",
    "        # save the training data\n",
    "        self.data = np.hstack((np.ones([X.shape[0],1]), X))\n",
    "        \n",
    "        # save the training labels\n",
    "        self.outputs = y\n",
    "        \n",
    "        # find the beta values that minimize the sum of squared errors\n",
    "        X = self.data\n",
    "        self.beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "                \n",
    "    # predict the output from input (testing) data\n",
    "    def predict(self, X):\n",
    "        # initialize an empty matrix to store the predicted outputs\n",
    "        yPredicted = np.empty([X.shape[0],1])\n",
    "        \n",
    "        # append a column of ones at the beginning of X\n",
    "        X = np.hstack((np.ones([X.shape[0],1]), X))\n",
    "        \n",
    "        # apply the function f with the values of beta from the fit function to each testing datapoint (rows of X)\n",
    "        for row in range(X.shape[0]):\n",
    "            yPredicted[row] = self.beta @ X[row,]\n",
    "            \n",
    "        return yPredicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Example\n",
    "\n",
    "Let's make up some 1D data and test the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted y values are [1.2 1.9 2.6 3.3 4. ]\n",
      "The real y values are [1 2 3 3 4]\n",
      "The beta values are [-3.   0.7]\n",
      "The r^2 score is 0.9423076923076923\n",
      "The mean squared error is 0.06\n",
      "The mean absolute error is 0.20000000000000054\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([[6], [7], [8], [9], [10]])\n",
    "y = np.array([1, 2, 3, 3, 4])\n",
    "\n",
    "model = OrdinaryLeastSquaresExact()\n",
    "model.fit(X,y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# print the predictions\n",
    "print('The predicted y values are', predictions.T[0])\n",
    "\n",
    "# print the real y values\n",
    "print('The real y values are', y)\n",
    "\n",
    "# print the beta values\n",
    "parameters = model.beta\n",
    "print('The beta values are', parameters)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X, y, label = 'Training Data')\n",
    "\n",
    "# plot the fitted model with the training data\n",
    "xModel = np.linspace(6,10,100)\n",
    "yModel = parameters[0] + parameters[1]*xModel\n",
    "lineFormula = 'y={:.3f}+{:.3f}x'.format(parameters[0], parameters[1])\n",
    "plt.plot(xModel, yModel, 'r', label = lineFormula)\n",
    "\n",
    "# add a legend\n",
    "plt.legend()\n",
    "\n",
    "# return quality metrics\n",
    "print('The r^2 score is', r2_score(y, predictions))\n",
    "print('The mean squared error is', mean_squared_error(y, predictions))\n",
    "print('The mean absolute error is', mean_absolute_error(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Example\n",
    "\n",
    "Let's make up some 2D data and test to see if our method works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r^2 score is 0.9642679900744417\n",
      "The mean squared error on the training set is 4.607999999999994\n",
      "The mean absolute error on the training set is 1.5360000000001235\n",
      "The predicted y values for the test set are [-6.52 19.08  6.6  32.2 ]\n",
      "The real y values for the test set are [ 9 15 25 31]\n",
      "The beta values are [-3.56 -6.24  9.52]\n",
      "The mean squared error on the test set is 149.37919999999122\n",
      "The mean absolute error on the test set is 9.799999999999963\n"
     ]
    }
   ],
   "source": [
    "trainX = np.array([[2, 2], [2, 3], [5, 6], [6, 7], [9, 10]])\n",
    "trainY = np.array([3, 13, 19, 29, 35])\n",
    "\n",
    "testX = np.array([[2, 1], [4, 5], [6, 5], [8, 9]])\n",
    "testY = np.array([9, 15, 25, 31])\n",
    "\n",
    "# instantiate an OLS model\n",
    "model = OrdinaryLeastSquaresExact()\n",
    "\n",
    "# fit the model to the training data (find the beta parameters)\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# return the predicted outputs for the datapoints in the training set\n",
    "trainPredictions = model.predict(trainX)\n",
    "\n",
    "# print the coefficient of determination r^2\n",
    "print('The r^2 score is', r2_score(trainY, trainPredictions))\n",
    "\n",
    "# print quality metrics\n",
    "print('The mean squared error on the training set is', mean_squared_error(trainY, trainPredictions))\n",
    "print('The mean absolute error on the training set is', mean_absolute_error(trainY, trainPredictions))\n",
    "\n",
    "# return the predicted outputs for the datapoints in the test set\n",
    "predictions = model.predict(testX)\n",
    "\n",
    "# print the predictions\n",
    "print('The predicted y values for the test set are', predictions.T[0])\n",
    "\n",
    "# print the real y values\n",
    "print('The real y values for the test set are', testY)\n",
    "\n",
    "# print the beta values\n",
    "print('The beta values are', model.beta)\n",
    "\n",
    "# print quality metrics\n",
    "print('The mean squared error on the test set is', mean_squared_error(testY, predictions))\n",
    "print('The mean absolute error on the test set is', mean_absolute_error(testY, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a low dimensional problem like this one, we can plot the points along with the function $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'y')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "n = 100\n",
    "\n",
    "# scatter plot of the test data\n",
    "x1 = testX[:,0]\n",
    "x2 = testX[:,1]\n",
    "y = testY\n",
    "ax.scatter(x1, x2, y, marker = 'o')\n",
    "\n",
    "# scatter plot of the training data\n",
    "x1 = trainX[:,0]\n",
    "x2 = trainX[:,1]\n",
    "y = trainY\n",
    "ax.scatter(x1, x2, y, marker = '^')\n",
    "\n",
    "# plot the plane we fit to the data\n",
    "beta = model.beta\n",
    "\n",
    "# surface plot\n",
    "x1 = np.linspace(0,10,10)\n",
    "x2 = np.linspace(0,10,10)\n",
    "\n",
    "X1, X2 = np.meshgrid(x1,x2)\n",
    "#Y = beta[0]*X1 + beta[1]*X2\n",
    "Y = beta[0] + beta[1]*X1 + beta[2]*X2\n",
    "\n",
    "surf = ax.plot_wireframe(X1, X2, Y)\n",
    "ax.view_init(10, 50)\n",
    "\n",
    "# add axis labels\n",
    "ax.set_xlabel('x_1')\n",
    "ax.set_ylabel('x_2')\n",
    "ax.set_zlabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: High School Graduation Rates in US States\n",
    "\n",
    "Let's try to use ordinary least squares on a real dataset. The CSV file in '/data/US_State_data.csv' contains data from each U.S. state.\n",
    "\n",
    "We would like to predict the output variable included, the high school graduation rate, from some input variables: including the crime rate (per 100,000 persons), the violent crime rate (per 100,000 persons), average teacher salary, student-to-teacher ratio, education expenditure per student, population density, and median household income.\n",
    "\n",
    "This means we have 50 examples (one for each state), 7 input (predictor) variables, and one output (response) variable. In order to use the formula we derived above to attack the problem with ordinary least squares, we need to find the matrices $X$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5f3161cb3487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import the data from the csv file to an numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/US_State_Data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "# import the data from the csv file to an numpy array\n",
    "data = pandas.read_csv('data/US_State_Data.csv', sep=',').to_numpy()\n",
    "#print(data)\n",
    "X = np.array(data[:,1:7], dtype=float)\n",
    "y = np.array(data[:,8], dtype=float)\n",
    "\n",
    "# split the data into training and test sets\n",
    "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "#trainX = normalize(trainX)\n",
    "#testX = normalize(testX)\n",
    "\n",
    "#trainX = scale(trainX)\n",
    "#testX = scale(testX)\n",
    "\n",
    "# run the model (same code as above)\n",
    "\n",
    "# instantiate an OLS model\n",
    "model = OrdinaryLeastSquaresExact()\n",
    "\n",
    "# fit the model to the training data (find the beta parameters)\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# return the predicted outputs for the datapoints in the training set\n",
    "trainPredictions = model.predict(trainX)\n",
    "\n",
    "# print the coefficient of determination r^2\n",
    "print('The r^2 score is', r2_score(trainY, trainPredictions))\n",
    "\n",
    "# print quality metrics\n",
    "print('The mean squared error on the training set is', mean_squared_error(trainY, trainPredictions))\n",
    "print('The mean absolute error on the training set is', mean_absolute_error(trainY, trainPredictions))\n",
    "\n",
    "# return the predicted outputs for the datapoints in the test set\n",
    "predictions = model.predict(testX)\n",
    "\n",
    "# print the predictions\n",
    "print('The predicted y values for the test set are', np.round(predictions.T[0],0))\n",
    "\n",
    "# print the real y values\n",
    "print('The real y values for the test set are     ', testY)\n",
    "\n",
    "# print the beta values\n",
    "print('The beta values are', model.beta)\n",
    "\n",
    "# print quality metrics\n",
    "print('The mean squared error on the test set is', mean_squared_error(testY, predictions))\n",
    "print('The mean absolute error on the test set is', mean_absolute_error(testY, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
